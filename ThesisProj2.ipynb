{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQVvcb07e9UH"
   },
   "source": [
    "# Thesis Project PART II\n",
    "This notebook contains the program which re-implemented the algorithms and learning models introduced in the paper of \"KE-GAN: Knowledge Embedded Generative Adversarial Networks for Semi-Supervised Scene Parsing\".\n",
    "In this part, the notebook expects to fulfill all implements in the original paper and starts to do all data testings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOXIZULnizxg"
   },
   "source": [
    "## Section 1: Basic Preparations\n",
    "This section contains some basic instruction sets used for prepare the pre-coded local python files for later notebook runnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "99hF4RjAfCte",
    "outputId": "e4824c29-1692-498c-e4cc-e1b2e35f3382"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/thesis/thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "56CKjukOg55V",
    "outputId": "324639ae-1bb1-4e65-efbc-ac458fcb190a"
   },
   "outputs": [],
   "source": [
    "# ! git clone https://AKI-maggie:Aki^6hyper@github.com/AKI-maggie/thesis.git\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XudVtnRBhAEk",
    "outputId": "a0330fbd-50fa-40b7-a6c9-3cafa50d76b9"
   },
   "outputs": [],
   "source": [
    "!cp -r * /content/\n",
    "%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iaeGIGJ5klFN",
    "outputId": "93a6f0e7-d8da-41ca-c6e7-3af706de0ef6"
   },
   "outputs": [],
   "source": [
    "!mkdir '/content/siftflow'\n",
    "!unzip \"/content/drive/My Drive/SiftFlowDataset.zip\" -d '/content/siftflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iy3JtAJIjjxQ"
   },
   "source": [
    "## Section 2: Model Running Section\n",
    "This section would call the python functions that builds the specified models for various data training experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAyxnZ3uj7UI"
   },
   "source": [
    "### Block 2.1: Data preparation\n",
    "This block contains the codes for loading data using the pre-defined python classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wE_gebPKjYzS"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import SiftFlowLoader\n",
    "import os\n",
    "# print(os.listdir('.'))\n",
    "img_path = 'siftflow/Images/spatial_envelope_256x256_static_8outdoorcategories/'\n",
    "label_path = 'siftflow/SemanticLabels/spatial_envelope_256x256_static_8outdoorcategories/'\n",
    "\n",
    "siftflow_dataset = SiftFlowLoader(img_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kv0a-lkujiBT",
    "outputId": "78b125ab-1afb-467f-9b28-4968e858d3d9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = siftflow_dataset.generate_training_batches(2)\n",
    "x1, y1 = next(t)\n",
    "\n",
    "x2, y2 = siftflow_dataset.generate_testing_dataset()\n",
    "\n",
    "print(y1.shape)\n",
    "# plt.imshow(x1[0])\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(38, 86))\n",
    "\n",
    "for i in range(33):\n",
    "    ax = f.add_subplot(17, 2, i+1)\n",
    "    ax.imshow(y1[0, :, :, i])\n",
    "\n",
    "ax = f.add_subplot(17, 2, i+1)\n",
    "ax.imshow(x1[0])\n",
    "# print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb3Y0D-5vpL-"
   },
   "source": [
    "### Block 2.2: Model experiments\n",
    "This block calls the model construction classes and do the training experiments on different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2tTM2ki4ti4s",
    "outputId": "77a98dac-6e8f-4328-9953-c2605c3e8595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Use the ConceptNet-based engine to build the knowledge graph ###\n",
      "Pre-trained graph exists, directly loading...\n",
      "The closest words for awning are: awning, moon, balcony\n",
      "[0.15 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.  ]\n",
      "The closest words for balcony are: balcony, building, door\n",
      "[0.         0.1696211  0.00769481 0.00763515 0.01570461 0.06925093\n",
      " 0.01104898 0.01188802 0.00355439 0.         0.00772817 0.02066947\n",
      " 0.0026907  0.0054216  0.00651941 0.00869487 0.00819327 0.01894596\n",
      " 0.00608461 0.00560111 0.0095607  0.01190267 0.00964116 0.01687588\n",
      " 0.00967814 0.00382397 0.00653314 0.01635494 0.0196211  0.\n",
      " 0.00686319 0.01568958 0.01835205]\n",
      "The closest words for bird are: bird, sea, sky\n",
      "[0.         0.00769481 0.1827014  0.02563932 0.02164642 0.02715816\n",
      " 0.00987006 0.01440332 0.01061661 0.         0.0251253  0.01317468\n",
      " 0.00787193 0.01558016 0.02034729 0.02365341 0.02611777 0.00867378\n",
      " 0.01835692 0.01548314 0.02772607 0.01531943 0.02193391 0.02930407\n",
      " 0.06029725 0.00492167 0.01110001 0.059973   0.00769481 0.\n",
      " 0.02244226 0.0547356  0.01380726]\n",
      "The closest words for boat are: boat, sea, river\n",
      "[0.         0.00763515 0.02563932 0.18577924 0.02325954 0.02694758\n",
      " 0.02307345 0.05227549 0.01235076 0.         0.02723566 0.0252294\n",
      " 0.00892232 0.01724916 0.02491906 0.01654128 0.02506269 0.0115895\n",
      " 0.01886258 0.01920268 0.05592911 0.0315216  0.02109691 0.02907079\n",
      " 0.05640288 0.01012694 0.02298357 0.02788504 0.00763515 0.\n",
      " 0.01520844 0.05283355 0.02400463]\n",
      "The closest words for bridge are: bridge, building, sky\n",
      "[0.         0.01570461 0.02164642 0.02325954 0.18830201 0.05542802\n",
      " 0.02334693 0.02732596 0.0136268  0.         0.02581748 0.02982059\n",
      " 0.01067766 0.02213227 0.02307472 0.02844672 0.03088203 0.01842203\n",
      " 0.02065681 0.01352264 0.05338319 0.0541155  0.05129165 0.03204051\n",
      " 0.0307708  0.01738568 0.0202048  0.05480265 0.01570461 0.\n",
      " 0.0228113  0.03064167 0.02493269]\n",
      "The closest words for building are: building, door, balcony\n",
      "[0.         0.06925093 0.02715816 0.02694758 0.05542802 0.24441506\n",
      " 0.03899641 0.04195771 0.01254489 0.         0.02727589 0.07295105\n",
      " 0.0094966  0.01913507 0.02300968 0.03068778 0.02891742 0.06686809\n",
      " 0.02147511 0.01976862 0.03374365 0.04200942 0.03402762 0.05956192\n",
      " 0.03415812 0.01349636 0.02305815 0.05772331 0.06925093 0.\n",
      " 0.02422301 0.05537499 0.06477194]\n",
      "The closest words for bus are: bus, door, car\n",
      "[0.         0.01104898 0.00987006 0.02307345 0.02334693 0.03899641\n",
      " 0.20219748 0.07766814 0.00566746 0.         0.01271501 0.07779239\n",
      " 0.00425016 0.00849532 0.01060807 0.01110397 0.01184891 0.02690103\n",
      " 0.00856566 0.01631516 0.02333535 0.07304684 0.01381648 0.02421806\n",
      " 0.01639442 0.02346774 0.03477122 0.01679953 0.01104898 0.\n",
      " 0.00863124 0.01999604 0.07097725]\n",
      "The closest words for car are: car, road, bus\n",
      "[0.         0.01188802 0.01440332 0.05227549 0.02732596 0.04195771\n",
      " 0.07766814 0.21886033 0.00787644 0.         0.01709364 0.07749491\n",
      " 0.00581978 0.01148302 0.01520373 0.0137101  0.01633361 0.02742132\n",
      " 0.01218347 0.03064883 0.03268432 0.08041262 0.01739513 0.02835341\n",
      " 0.025408   0.02583415 0.06939883 0.02130221 0.01188802 0.\n",
      " 0.01106687 0.03090198 0.07014304]\n",
      "The closest words for cow are: cow, fence, field\n",
      "[0.         0.00355439 0.01061661 0.01235076 0.0136268  0.01254489\n",
      " 0.00566746 0.00787644 0.22682222 0.         0.0288111  0.0071002\n",
      " 0.10605172 0.10172081 0.08063338 0.01364862 0.01586542 0.00425553\n",
      " 0.02858969 0.00785162 0.02559088 0.01013251 0.03111559 0.01804169\n",
      " 0.01635882 0.00325527 0.00618205 0.0144482  0.00355439 0.\n",
      " 0.01235209 0.02685357 0.00758312]\n",
      "The closest words for crosswalk are: crosswalk, window, moon\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15 0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.  ]\n",
      "The closest words for desert are: desert, sea, sun\n",
      "[0.         0.00772817 0.0251253  0.02723566 0.02581748 0.02727589\n",
      " 0.01271501 0.01709364 0.0288111  0.         0.19856068 0.01579698\n",
      " 0.02558779 0.05799997 0.03281853 0.03635296 0.02636117 0.00934081\n",
      " 0.01974004 0.01052858 0.05607172 0.02108964 0.03521225 0.05618178\n",
      " 0.06060078 0.00677546 0.01099001 0.04044205 0.00772817 0.\n",
      " 0.05999939 0.03159967 0.01904905]\n",
      "The closest words for door are: door, bus, car\n",
      "[0.         0.02066947 0.01317468 0.0252294  0.02982059 0.07295105\n",
      " 0.07779239 0.07749491 0.0071002  0.         0.01579698 0.2210341\n",
      " 0.00533816 0.01069336 0.01321799 0.01484221 0.01525432 0.06885151\n",
      " 0.0111144  0.01794845 0.02650497 0.07327231 0.01783437 0.03124812\n",
      " 0.02021419 0.02354018 0.03534511 0.02417672 0.02066947 0.\n",
      " 0.01159326 0.02674499 0.07484709]\n",
      "The closest words for fence are: fence, cow, field\n",
      "[0.         0.0026907  0.00787193 0.00892232 0.01067766 0.0094966\n",
      " 0.00425016 0.00581978 0.10605172 0.         0.02558779 0.00533816\n",
      " 0.21296931 0.09735421 0.04913121 0.01138936 0.01212983 0.00321246\n",
      " 0.01928212 0.00541501 0.01825395 0.00749282 0.02662654 0.01461946\n",
      " 0.01290758 0.00240722 0.00443485 0.01143562 0.0026907  0.\n",
      " 0.01053152 0.01824032 0.00584317]\n",
      "The closest words for field are: field, cow, fence\n",
      "[0.         0.0054216  0.01558016 0.01724916 0.02213227 0.01913507\n",
      " 0.00849532 0.01148302 0.10172081 0.         0.05799997 0.01069336\n",
      " 0.09735421 0.23086845 0.07868692 0.02475187 0.02464474 0.00645752\n",
      " 0.03482666 0.0100092  0.03487297 0.01479472 0.05888936 0.03109743\n",
      " 0.02690128 0.0047531  0.00851809 0.02389168 0.0054216  0.\n",
      " 0.02323421 0.03319213 0.01194876]\n",
      "The closest words for grass are: grass, cow, field\n",
      "[0.         0.00651941 0.02034729 0.02491906 0.02307472 0.02300968\n",
      " 0.01060807 0.01520373 0.08063338 0.         0.03281853 0.01321799\n",
      " 0.04913121 0.07868692 0.21103187 0.01942921 0.02846634 0.00785327\n",
      " 0.06495313 0.01720445 0.0528686  0.01952637 0.04078703 0.02799325\n",
      " 0.02722819 0.00627323 0.01263801 0.02385956 0.00651941 0.\n",
      " 0.01639567 0.06032435 0.01336448]\n",
      "The closest words for moon are: moon, sun, sky\n",
      "[0.         0.00869487 0.02365341 0.01654128 0.02844672 0.03068778\n",
      " 0.01110397 0.0137101  0.01364862 0.         0.03635296 0.01484221\n",
      " 0.01138936 0.02475187 0.01942921 0.19687175 0.0292236  0.00979009\n",
      " 0.02117379 0.00924382 0.02570251 0.01604993 0.05936064 0.05820436\n",
      " 0.03278842 0.00515636 0.00893151 0.06505855 0.00869487 0.\n",
      " 0.06835293 0.02891525 0.01879251]\n",
      "The closest words for mountain are: mountain, sky, rock\n",
      "[0.         0.00819327 0.02611777 0.02506269 0.03088203 0.02891742\n",
      " 0.01184891 0.01633361 0.01586542 0.         0.02636117 0.01525432\n",
      " 0.01212983 0.02464474 0.02846634 0.0292236  0.18515967 0.00953653\n",
      " 0.02677564 0.01602185 0.0528896  0.02150315 0.05529855 0.03141526\n",
      " 0.03198458 0.00690831 0.01282066 0.05531705 0.00819327 0.\n",
      " 0.02321666 0.05446087 0.01533191]\n",
      "The closest words for person are: person, door, building\n",
      "[0.         0.01894596 0.00867378 0.0115895  0.01842203 0.06686809\n",
      " 0.02690103 0.02742132 0.00425553 0.         0.00934081 0.06885151\n",
      " 0.00321246 0.00645752 0.00785327 0.00979009 0.00953653 0.18029118\n",
      " 0.00702966 0.00836466 0.01326406 0.02639557 0.01119342 0.01960052\n",
      " 0.01180351 0.0084801  0.0132924  0.01749702 0.01894596 0.\n",
      " 0.00769769 0.01765673 0.03134238]\n",
      "The closest words for plant are: plant, grass, tree\n",
      "[0.         0.00608461 0.01835692 0.01886258 0.02065681 0.02147511\n",
      " 0.00856566 0.01218347 0.02858969 0.         0.01974004 0.0111144\n",
      " 0.01928212 0.03482666 0.06495313 0.02117379 0.02677564 0.00702966\n",
      " 0.18621652 0.01644754 0.02679273 0.01410554 0.05780963 0.0272333\n",
      " 0.01991901 0.00453168 0.01076477 0.02149426 0.00608461 0.\n",
      " 0.01351469 0.05982138 0.01187749]\n",
      "The closest words for pole are: pole, sign, tree\n",
      "[0.         0.00560111 0.01548314 0.01920268 0.01352264 0.01976862\n",
      " 0.01631516 0.03064883 0.00785162 0.         0.01052858 0.01794845\n",
      " 0.00541501 0.0100092  0.01720445 0.00924382 0.01602185 0.00836466\n",
      " 0.01644754 0.1890329  0.01719423 0.03053359 0.01363427 0.01756254\n",
      " 0.01449269 0.00980952 0.07740043 0.01423007 0.00560111 0.\n",
      " 0.00721836 0.05728986 0.01567088]\n",
      "The closest words for river are: river, sea, desert\n",
      "[0.         0.0095607  0.02772607 0.05592911 0.05338319 0.03374365\n",
      " 0.02333535 0.03268432 0.02559088 0.         0.05607172 0.02650497\n",
      " 0.01825395 0.03487297 0.0528686  0.02570251 0.0528896  0.01326406\n",
      " 0.02679273 0.01719423 0.20537767 0.05385269 0.0375684  0.03711627\n",
      " 0.06127203 0.01730124 0.02250367 0.04198406 0.0095607  0.\n",
      " 0.02640015 0.04416569 0.02322912]\n",
      "The closest words for road are: road, car, sidewalk\n",
      "[0.         0.01190267 0.01531943 0.0315216  0.0541155  0.04200942\n",
      " 0.07304684 0.08041262 0.01013251 0.         0.02108964 0.07327231\n",
      " 0.00749282 0.01479472 0.01952637 0.01604993 0.02150315 0.02639557\n",
      " 0.01410554 0.03053359 0.05385269 0.23325976 0.02353404 0.02667265\n",
      " 0.02592295 0.07493932 0.06997215 0.02706803 0.01190267 0.\n",
      " 0.01358748 0.02942344 0.04688903]\n",
      "The closest words for rock are: rock, moon, field\n",
      "[0.         0.00964116 0.02193391 0.02109691 0.05129165 0.03402762\n",
      " 0.01381648 0.01739513 0.03111559 0.         0.03521225 0.01783437\n",
      " 0.02662654 0.05888936 0.04078703 0.05936064 0.05529855 0.01119342\n",
      " 0.05780963 0.01363427 0.0375684  0.02353404 0.20609534 0.05733992\n",
      " 0.03164307 0.00756078 0.01258152 0.04327429 0.00964116 0.\n",
      " 0.03032029 0.04361575 0.02064328]\n",
      "The closest words for sand are: sand, building, moon\n",
      "[0.         0.01687588 0.02930407 0.02907079 0.03204051 0.05956192\n",
      " 0.02421806 0.02835341 0.01804169 0.         0.05618178 0.03124812\n",
      " 0.01461946 0.03109743 0.02799325 0.05820436 0.03141526 0.01960052\n",
      " 0.0272333  0.01756254 0.03711627 0.02667265 0.05733992 0.20232151\n",
      " 0.05690754 0.00856912 0.01672229 0.04475318 0.01687588 0.\n",
      " 0.03491304 0.05533986 0.05046838]\n",
      "The closest words for sea are: sea, sky, river\n",
      "[0.         0.00967814 0.06029725 0.05640288 0.0307708  0.03415812\n",
      " 0.01639442 0.025408   0.01635882 0.         0.06060078 0.02021419\n",
      " 0.01290758 0.02690128 0.02722819 0.03278842 0.03198458 0.01180351\n",
      " 0.01991901 0.01449269 0.06127203 0.02592295 0.03164307 0.05690754\n",
      " 0.20499089 0.00832826 0.01492786 0.06266963 0.00967814 0.\n",
      " 0.03296971 0.0438238  0.02270049]\n",
      "The closest words for sidewalk are: sidewalk, road, car\n",
      "[0.         0.00382397 0.00492167 0.01012694 0.01738568 0.01349636\n",
      " 0.02346774 0.02583415 0.00325527 0.         0.00677546 0.02354018\n",
      " 0.00240722 0.0047531  0.00627323 0.00515636 0.00690831 0.0084801\n",
      " 0.00453168 0.00980952 0.01730124 0.07493932 0.00756078 0.00856912\n",
      " 0.00832826 0.17407574 0.02247994 0.00869614 0.00382397 0.\n",
      " 0.00436525 0.00945286 0.01506403]\n",
      "The closest words for sign are: sign, pole, road\n",
      "[0.         0.00653314 0.01110001 0.02298357 0.0202048  0.02305815\n",
      " 0.03477122 0.06939883 0.00618205 0.         0.01099001 0.03534511\n",
      " 0.00443485 0.00851809 0.01263801 0.00893151 0.01282066 0.0132924\n",
      " 0.01076477 0.07740043 0.02250367 0.06997215 0.01258152 0.01672229\n",
      " 0.01492786 0.02247994 0.20374144 0.01422654 0.00653314 0.\n",
      " 0.00724234 0.03152894 0.02818813]\n",
      "The closest words for sky are: sky, moon, sun\n",
      "[0.         0.01635494 0.059973   0.02788504 0.05480265 0.05772331\n",
      " 0.01679953 0.02130221 0.0144482  0.         0.04044205 0.02417672\n",
      " 0.01143562 0.02389168 0.02385956 0.06505855 0.05531705 0.01749702\n",
      " 0.02149426 0.01423007 0.04198406 0.02706803 0.04327429 0.04475318\n",
      " 0.06266963 0.00869614 0.01422654 0.21473078 0.01635494 0.\n",
      " 0.06466883 0.0437332  0.02399492]\n",
      "The closest words for staircase are: staircase, building, door\n",
      "[0.         0.0196211  0.00769481 0.00763515 0.01570461 0.06925093\n",
      " 0.01104898 0.01188802 0.00355439 0.         0.00772817 0.02066947\n",
      " 0.0026907  0.0054216  0.00651941 0.00869487 0.00819327 0.01894596\n",
      " 0.00608461 0.00560111 0.0095607  0.01190267 0.00964116 0.01687588\n",
      " 0.00967814 0.00382397 0.00653314 0.01635494 0.1696211  0.\n",
      " 0.00686319 0.01568958 0.01835205]\n",
      "The closest words for streetlight are: streetlight, window, car\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.15 0.   0.   0.  ]\n",
      "The closest words for sun are: sun, moon, sky\n",
      "[0.         0.00686319 0.02244226 0.01520844 0.0228113  0.02422301\n",
      " 0.00863124 0.01106687 0.01235209 0.         0.05999939 0.01159326\n",
      " 0.01053152 0.02323421 0.01639567 0.06835293 0.02321666 0.00769769\n",
      " 0.01351469 0.00721836 0.02640015 0.01358748 0.03032029 0.03491304\n",
      " 0.03296971 0.00436525 0.00724234 0.06466883 0.00686319 0.\n",
      " 0.19193514 0.02214206 0.01324257]\n",
      "The closest words for tree are: tree, grass, plant\n",
      "[0.         0.01568958 0.0547356  0.05283355 0.03064167 0.05537499\n",
      " 0.01999604 0.03090198 0.02685357 0.         0.03159967 0.02674499\n",
      " 0.01824032 0.03319213 0.06032435 0.02891525 0.05446087 0.01765673\n",
      " 0.05982138 0.05728986 0.04416569 0.02942344 0.04361575 0.05533986\n",
      " 0.0438238  0.00945286 0.03152894 0.0437332  0.01568958 0.\n",
      " 0.02214206 0.21811278 0.0277143 ]\n",
      "The closest words for window are: window, door, bus\n",
      "[0.         0.01835205 0.01380726 0.02400463 0.02493269 0.06477194\n",
      " 0.07097725 0.07014304 0.00758312 0.         0.01904905 0.07484709\n",
      " 0.00584317 0.01194876 0.01336448 0.01879251 0.01533191 0.03134238\n",
      " 0.01187749 0.01567088 0.02322912 0.04688903 0.02064328 0.05046838\n",
      " 0.02270049 0.01506403 0.02818813 0.02399492 0.01835205 0.\n",
      " 0.01324257 0.0277143  0.20144948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 8, 8, 2048)   205522944   conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool4_upsampling (Conv2D)       (None, 16, 16, 34)   34850       conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 8, 8, 2048)   4196352     conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool4_upsampling2 (Conv2DTransp (None, 32, 32, 34)   4624        pool4_upsampling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool3_upsampling (Conv2D)       (None, 32, 32, 34)   17442       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv7_upsampling (Conv2DTranspo (None, 32, 32, 34)   1114112     conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fcn_addition8 (Add)             (None, 32, 32, 34)   0           pool4_upsampling2[0][0]          \n",
      "                                                                 pool3_upsampling[0][0]           \n",
      "                                                                 conv7_upsampling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "final_model8 (Conv2DTranspose)  (None, 256, 256, 34) 73984       fcn_addition8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 34) 0           final_model8[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 234,552,020\n",
      "Trainable params: 234,498,900\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.kegan import Kegan\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from loss.comb_loss import combination_loss\n",
    "\n",
    "# build a model trained for a SiftFlow dataset\n",
    "d_optimizer = Adam(lr=0.000001, beta_1=0.9, decay=0.0001, clipvalue=5.0)\n",
    "gan_optimizer = Adam(lr=0.000001, beta_1=0.5)\n",
    "kegan = Kegan(256, 256, 33, d_optimizer, gan_optimizer, fcn_level=8, use_pyramid = False,\\\n",
    "              save_path='./nossp_fcn8.h5')#,\\\n",
    "            #   d_loss= combination_loss)\n",
    "\n",
    "print(\"D:\")\n",
    "kegan.d_model.summary()\n",
    "# print(\"G:\")\n",
    "# kegan.g_model.summary()\n",
    "# print(\"GAN:\")\n",
    "# kegan.gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yZinE-5iyJec",
    "outputId": "80502ddc-4379-47d8-f446-c732692a578e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights found\n",
      "### Start Training ###\n",
      "=======================================================\n",
      "Training Procedure 1\n",
      "Train on 52 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " 8/52 [===>..........................] - ETA: 7:41 - loss: 1.6573 - accuracy: 0.4785"
     ]
    }
   ],
   "source": [
    "# prepare training data loader\n",
    "# iterator = siftflow_dataset.generate_training_batches(24)\n",
    "# # manually enumerate epochs\n",
    "# print(\"### Start Training ###\")\n",
    "# x_real, y_real = [], []\n",
    "# for i in range(5):\n",
    "#     print(\"=======================================================\")\n",
    "#     del x_real\n",
    "#     del y_real\n",
    "#     print(\"Training Procedure {0}\".format(i+1))\n",
    "#     x_real, y_real = next(iterator)\n",
    "#     print(x_real.shape)\n",
    "    # get randomly selected 'real' samples\n",
    "    \n",
    "    # update discriminator on real samples\n",
    "    # kegan.d_train(x_real, y_real, batch_size=8, epochs=10, \n",
    "    #             validation_data=siftflow_dataset.test_data)# callbacks = [LambdaCallback(on_epoch_end=lambda batch, logs: print(model.get_weights(-2)))])\n",
    "\n",
    "from main import train\n",
    "\n",
    "train(kegan, siftflow_dataset, n_iter = 100, n_batch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model trained for a SiftFlow dataset\n",
    "del kegan\n",
    "d_optimizer = Adam(lr=0.000001, beta_1=0.9, decay=0.0001, clipvalue=5.0)\n",
    "gan_optimizer = Adam(lr=0.000001, beta_1=0.5)\n",
    "kegan = Kegan(256, 256, 33, d_optimizer, gan_optimizer, fcn_level=8, use_pyramid = True,\\\n",
    "              save_path='./ssp_fcn8.h5')#,\\\n",
    "            #   d_loss= combination_loss)\n",
    "\n",
    "print(\"D:\")\n",
    "kegan.d_model.summary()\n",
    "# print(\"G:\")\n",
    "# kegan.g_model.summary()\n",
    "# print(\"GAN:\")\n",
    "# kegan.gan_model.summary()\n",
    "train(kegan, siftflow_dataset, n_iter = 100, n_batch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wiw4owaEIoff",
    "outputId": "42bd198a-29a2-4dc6-a5d9-4b3ce8e3f4c8"
   },
   "outputs": [],
   "source": [
    "iterator = siftflow_dataset.generate_training_batches(20)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"=======================================================\")\n",
    "    print(\"Training Procedure {0}\".format(i+1))\n",
    "\t# get randomly selected 'real' samples\n",
    "    x_real, y_real = next(iterator)\n",
    "    kegan.gan_train(x_real, y_real, batch_size=20, epochs=10, \n",
    "        validation_data=siftflow_dataset.generate_testing_dataset()) #callbacks = [LambdaCallback(on_epoch_end=lambda batch, logs: print(model.get_weights(-2)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9MaSnRWbxDMV",
    "outputId": "9ca2cff3-a605-4759-c125-e3cd7641f34b"
   },
   "outputs": [],
   "source": [
    "test = kegan.g_model.predict()\n",
    "\n",
    "x, y = test\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "CH-QbIKrL9JZ",
    "outputId": "80fe5e71-e0f1-4c97-b9c9-40f081306c10"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x[9, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWHuN--WL_Cw"
   },
   "outputs": [],
   "source": [
    "# functions used for display some predicting results\n",
    "\n",
    "\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "\n",
    "# output the original images, the predictions, and the label images\n",
    "def show_results(test_data, test_predicts, test_labels, n_classes):\n",
    "    # store all ious for late miou\n",
    "    ious = []\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        img  = test_data[i]\n",
    "        seg = test_predicts[i]\n",
    "        segtest = test_labels[i]\n",
    "\n",
    "        fig = plt.figure(figsize=(20,60))    \n",
    "        ax = fig.add_subplot(1,6,1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(\"original\")\n",
    "        \n",
    "        print(seg.shape)\n",
    "\n",
    "        ax = fig.add_subplot(1,6,2)\n",
    "        ax.imshow(give_color_to_seg_img(seg,n_classes))\n",
    "        ax.set_title(\"predicted class\")\n",
    "\n",
    "        ax = fig.add_subplot(1,6,3)\n",
    "        ax.imshow(rgb2gray(give_color_to_seg_img(seg,n_classes)), cmap=\"Reds_r\")\n",
    "        ax.set_title(\"predicted class grey-scale\")\n",
    "\n",
    "        ax = fig.add_subplot(1,6,4)\n",
    "        ax.imshow(give_color_to_seg_img(segtest,n_classes))\n",
    "        ax.set_title(\"true class\")\n",
    "\n",
    "        ax = fig.add_subplot(1,6,5)\n",
    "        ax.imshow(rgb2gray(give_color_to_seg_img(segtest,n_classes)), cmap=\"Blues_r\")\n",
    "        ax.set_title(\"true class grey-scale\")\n",
    "        \n",
    "        ax = fig.add_subplot(1,6,6)\n",
    "        ax.imshow(rgb2gray(give_color_to_seg_img(seg,n_classes)), cmap=\"Reds_r\", alpha=0.7)\n",
    "        ax.imshow(rgb2gray(give_color_to_seg_img(segtest,n_classes)), cmap=\"Blues_r\", alpha=0.5)\n",
    "        ax.set_title(\"IoU class\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        iou = check_IoU(seg, segtest)\n",
    "        print(\"IoU result: %.2f%%\" % iou)\n",
    "        \n",
    "        ious.append(iou)\n",
    "    \n",
    "    # calculate mIoU\n",
    "    miou = sum(ious)/len(ious)\n",
    "    print(\"\\nmIoU: %.2f%%\\n\"%miou)\n",
    "        \n",
    "# Add IoU score calculation to the prediction comparation of the testing data\n",
    "# return in percentage\n",
    "def check_IoU(prediction, ground_true):\n",
    "#     print(prediction)\n",
    "#     print(ground_true)\n",
    "    intersection = np.logical_and(prediction, ground_true)\n",
    "    union = np.logical_or(prediction, ground_true)\n",
    "    IoU_score = np.sum(intersection)/np.sum(union) * 100\n",
    "#     print(intersection)\n",
    "#     print(union)\n",
    "    return IoU_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTKMp3UI4EbG"
   },
   "outputs": [],
   "source": [
    "# t = siftflow_dataset.generate_testing_dataset(10)\n",
    "\n",
    "t = kegan.g_model.predict()\n",
    "predict = kegan.d_model.predict(t)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "RTAVR8d34QES",
    "outputId": "c06d8156-c81a-4ee4-fb1b-e1f9846ee51d"
   },
   "outputs": [],
   "source": [
    "print(predict.shape)\n",
    "plt.imshow(t[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "1Ng2QZhs4XJG",
    "outputId": "0b240fbd-877a-4f06-d35e-7c3367e03839"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# fcn8\n",
    "predict_img = np.argmax(predict, axis=2)\n",
    "\n",
    "# show fcn8 result\n",
    "plt.imshow(give_color_to_seg_img(predict_img, 33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "-Uv2pjcy4mt9",
    "outputId": "4d2a0edd-ec7c-4957-84ee-3167ff35605f"
   },
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjwq-DB8E82Z"
   },
   "source": [
    "## Section 2\n",
    "This section does the segmentation experiment tested on SiftFlow Dataset"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ThesisProj2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
